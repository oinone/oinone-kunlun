import { ConfigHelper } from '@oinone/kunlun-engine';
import { RuntimeConfig } from '@oinone/kunlun-meta';
import { uniqueKeyGenerator } from '@oinone/kunlun-shared';
import { get as getValue, set as setValue } from 'lodash-es';
import {
  CdnFileMultipartUploadData,
  CdnFileSingleUploadData,
  createResourceFile,
  getFileSignature,
  UploadChunkFile
} from './UploadService';

interface IUploadedPartHeader {
  partNumber: string;
  headers: Record<string, any>;
}

type Fn = (...arg) => unknown;

export interface MultipartUploadRuntimeConfig {
  partSize?: number;
  parallel?: number;
  chunkUploadThreshold?: number;

  [key: string]: unknown;
}

export enum IUploadMethod {
  Single = 'Single',
  Multipart = 'Multipart'
}

export interface IUploadFileEventParams {
  /**
   * ä¸Šä¼ çš„æ–‡ä»¶
   */
  file: File;

  /**
   * æŽ¥å—æ–‡ä»¶ç±»åž‹
   */
  accept?: string;

  /**
   * cdn key
   */
  cdnKey?: string;

  /**
   * æ˜¯å¦é€šè¿‡PamirsFileç®¡ç†æ–‡ä»¶
   */
  managed?: boolean;

  /**
   * ä¸Šä¼ æ–¹å¼ï¼Œé˜ˆå€¼ï¼š[ç›´ä¼ ã€åˆ†ç‰‡ä¸Šä¼ ]
   */
  uploadMethod?: IUploadMethod;

  /**
   * åˆ†ç‰‡å¤§å°, å•ä½M
   */
  partSize?: number;

  /**
   * æ–‡ä»¶å¤§å° å¤§äºŽ æŸä¸ªå€¼çš„æ—¶å€™å¼€å¯åˆ†ç‰‡ä¸Šä¼ 
   */
  chunkUploadThreshold?: number;

  /**
   * å¹¶å‘æ•°é‡
   */
  parallel?: number;

  /**
   * ä¸Šä¼ æˆåŠŸ
   */
  onSuccess?: Fn;

  /**
   * ä¸Šä¼ å¤±è´¥
   */
  onError?: Fn;

  /**
   * ä¸Šä¼ ä¸­
   */
  onProgress?: Fn;
}

// å°†å“åº”å¤´å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¯¹è±¡çš„è¾…åŠ©å‡½æ•°
function headersToObject(headers) {
  var result = {};
  var headersArray = headers.trim().split(/[\r\n]+/);

  headersArray.forEach(function (line) {
    var parts = line.split(': ');
    var header = parts.shift();
    var value = parts.join(': ');
    result[header] = value;
  });

  return result;
}

/**
 * ä½¿ç”¨åˆ†å—ä¸Šä¼ æŠ€æœ¯ä¸Šä¼ å¤§æ–‡ä»¶åˆ°OSS
 *
 * @param multipartUploadData åŒ…å«ä¸Šä¼ æ•°æ®åˆ—è¡¨å’Œå®Œæˆä¸Šä¼ æ‰€éœ€çš„é…ç½®çš„å¯¹è±¡ã€‚
 * @param file è¦ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡ã€‚
 * @param fileChunks
 * @param chunkSize æ¯ä¸ªåˆ†å—çš„å¤§å°ã€‚
 * @param managed ä¸Šä¼ æˆåŠŸåŽï¼Œè‡ªåŠ¨æ‰˜ç®¡åˆ°OSS
 * @param onSuccess ä¸Šä¼ æˆåŠŸæ—¶çš„å›žè°ƒå‡½æ•°ï¼ŒæŽ¥æ”¶ä¸Šä¼ å®Œæˆçš„æ–‡ä»¶å¯¹è±¡å’ŒåŽŸå§‹æ–‡ä»¶å¯¹è±¡ä½œä¸ºå‚æ•°ã€‚
 * @param onError ä¸Šä¼ å¤±è´¥æ—¶çš„å›žè°ƒå‡½æ•°ï¼ŒæŽ¥æ”¶é”™è¯¯ä¿¡æ¯å’ŒåŽŸå§‹æ–‡ä»¶å¯¹è±¡ä½œä¸ºå‚æ•°ã€‚
 * @param onProgress ä¸Šä¼ è¿‡ç¨‹ä¸­çš„è¿›åº¦å›žè°ƒå‡½æ•°ï¼ŒæŽ¥æ”¶å½“å‰ä¸Šä¼ è¿›åº¦çš„ç™¾åˆ†æ¯”ã€æ–‡ä»¶å¯¹è±¡å’ŒçŠ¶æ€ä¿¡æ¯ä½œä¸ºå‚æ•°ã€‚
 */
const useMultipartUpload = async (params: {
  multipartUploadData: CdnFileMultipartUploadData;
  file: File;
  fileChunks: Blob[];
  chunkSize: number;
  downloadUrl: string;
  parallel: number;
  managed?: boolean;
  onSuccess?: Fn;
  onError?: Fn;
  onProgress?: Fn;
}) => {
  const { multipartUploadData, file, fileChunks, parallel, chunkSize, downloadUrl, onSuccess, onError, onProgress } =
    params;
  const { uploadDataList, completeUploadData } = multipartUploadData;

  let uploadedChunks = 0;
  let index = 0;
  const uploadedPartHeaders: IUploadedPartHeader[] = [];

  /**
   * ä¸Šä¼ å•ä¸ªåˆ†å—åˆ°CDNã€‚
   * @param chunk è¦ä¸Šä¼ çš„åˆ†å—æ•°æ®ã€‚
   * @param index åˆ†å—çš„ç´¢å¼•ã€‚
   * @returns è¿”å›žä¸€ä¸ªPromiseï¼ŒæˆåŠŸæ—¶è§£æžä¸ºtrueï¼Œå¤±è´¥æ—¶rejectä¸€ä¸ªé”™è¯¯ã€‚
   */
  const uploadChunk = async (chunk, index) => {
    return new Promise((resolve, reject) => {
      const partNumber = `${index + 1}`;

      const uploadData = uploadDataList[index];
      const { httpMethod, uploadUrl, uploadHeaders, uploadFormData } = uploadData;
      let formData: FormData | undefined;
      if (uploadFormData) {
        formData = new FormData();
        Object.entries(uploadFormData).forEach(([key, value]) => {
          formData!.append(key, value);
        });
        formData.append('file', chunk);
      }

      // åˆ›å»ºXMLHttpRequestå¹¶é…ç½®ä¸Šä¼ è¿‡ç¨‹çš„ç›‘æŽ§
      const xhr = new XMLHttpRequest();
      xhr.open(httpMethod || 'POST', uploadUrl);

      if (uploadHeaders) {
        Object.entries(uploadHeaders).forEach(([key, value]) => {
          xhr.setRequestHeader(key, value);
        });
      }

      xhr.upload.onprogress = ({ total, loaded }) => {
        onProgress?.({
          percent: Number.parseFloat(Math.round(((uploadedChunks * chunkSize + loaded) / file.size) * 100).toFixed(2)),
          file,
          status: 'ä¸Šä¼ ä¸­...'
        });
      };

      // å¤„ç†ä¸Šä¼ å“åº”
      xhr.onreadystatechange = function () {
        if (xhr.readyState === 4 && xhr.status === 200) {
          // èŽ·å–æ‰€æœ‰çš„å“åº”å¤´
          const allHeaders = xhr.getAllResponseHeaders();
          const headersObject = headersToObject(allHeaders);

          uploadedPartHeaders.push({
            partNumber,
            headers: headersObject
          });
        }
      };

      xhr.onload = (response) => {
        if ([200, 204].includes(xhr.status)) {
          uploadedChunks++;
          resolve(true);
        } else {
          reject(new Error(`Chunk ${index} upload failed`));
        }
      };

      xhr.onerror = (err) => {
        onError?.(err);
        reject(new Error(`Chunk ${index} upload failed`));
      };

      xhr.send(formData || chunk);
    });
  };

  // ä¸Šä¼ å®Œæˆ
  const completeMultipartUpload = async () => {
    const partXML: string[] = [];
    const parts: any[] = [];

    const {
      uploadUrl: uploadCompleteUrl,
      uploadHeaders: uploadCompleteHeaders,
      uploadData: uploadCompleteData,
      uploadPartData: uploadCompletePartData,
      uploadPartContext: uploadCompletePartContext
    } = completeUploadData;

    uploadedPartHeaders
      .sort((a, b) => Number(a.partNumber) - Number(b.partNumber))
      .forEach((opt) => {
        const headerMap: Record<string, any> = {};

        Object.entries(uploadCompletePartContext || {}).map(([k, v]) => {
          const value = getValue(opt, v);
          setValue(headerMap, k, value);
        });

        parts.push(headerMap);

        const xmlString = new Function('partNumber', 'response', `return ${uploadCompletePartData}`)(
          opt.partNumber,
          headerMap.response
        );

        partXML.push(xmlString);
      });

    const allXML = new Function('parts', `return ${uploadCompleteData}`)(partXML.join(''));

    const xhr = new XMLHttpRequest();
    xhr.open('POST', uploadCompleteUrl!);

    if (uploadCompleteHeaders) {
      Object.entries(uploadCompleteHeaders).forEach(([key, value]) => {
        xhr.setRequestHeader(key, value);
      });
    }

    xhr.send(allXML);
  };

  // å¼€å§‹ä¸Šä¼ 
  const continuedUpload = async () => {
    try {
      while (index < fileChunks.length) {
        const chunks = fileChunks.slice(index, index + parallel);
        await Promise.all(
          chunks.map(async (chunk, i) => {
            await uploadChunk(chunk, index + i);
          })
        );

        index += parallel;
      }

      index = 0;
      // æ‰€æœ‰åˆ†å—ä¸Šä¼ æˆåŠŸåŽï¼Œé€šçŸ¥æœåŠ¡å™¨åˆå¹¶åˆ†å—
      await completeMultipartUpload();

      let rst;
      if (params.managed) {
        rst = await createResourceFile('', downloadUrl, file.size, file.name);
      } else {
        rst = {
          id: uniqueKeyGenerator(),
          name: file.name,
          size: file.size,
          url: downloadUrl
        };
      }

      onSuccess?.(rst, downloadUrl);
      return;
    } catch (error: any) {
      // ä¸Šä¼ å¤±è´¥çš„æ—¶å€™ï¼Œå…è®¸ä»Žå¤±è´¥çš„åœ°æ–¹ä»Žæ–°ä¸Šä¼ 
      // const headers = uploadedPartHeaders.sort((a, b) => Number(a.partNumber) - Number(b.partNumber));
      // const [lastHeader] = headers.slice(-1);

      // if (lastHeader && lastHeader.partNumber) {
      //   index = Number(lastHeader.partNumber) - 1;
      // }

      console.error('ðŸš€ ~ multiPartRequest ~ error:', error);
      onError?.({ [file.name]: `ä¸Šä¼ å¤±è´¥: ${error.message}` }, file);
    }
  };

  continuedUpload();

  return { continuedUpload };
};

const useSingleUpload = async (params: {
  singleUploadData: CdnFileSingleUploadData;
  file: File;
  downloadUrl: string;
  expandData?: Record<string, any>;
  managed?: boolean;
  onSuccess?: Fn;
  onError?: Fn;
  onProgress?: Fn;
}) => {
  const continuedUpload = async () => {
    const { singleUploadData, file, expandData, downloadUrl, onSuccess, onError, onProgress } = params;
    const formData = new FormData();
    const { uploadFormData, uploadHeaders, uploadUrl } = singleUploadData!;

    const data = Object.assign(uploadFormData || {}, expandData || {}, {});

    Object.keys(data).forEach((key) => {
      formData.append(key, data[key]);
    });

    formData.append('file', file);

    const xhr = new XMLHttpRequest();

    if (xhr !== null) {
      xhr.open('POST', uploadUrl);

      if (uploadHeaders) {
        Object.entries(uploadHeaders).forEach(([key, value]) => {
          xhr.setRequestHeader(key, value);
        });
      }

      xhr.onerror = onError || (() => {});
      xhr.upload.onprogress = ({ total, loaded }) => {
        onProgress?.({
          percent: Number.parseFloat(Math.round((loaded / total) * 100).toFixed(2)),
          file,
          status: 'ä¸Šä¼ ä¸­...'
        });
      };
      xhr.onload = async (response) => {
        if ([200, 204].includes(xhr.status)) {
          let rst;
          if (params.managed) {
            rst = await createResourceFile('', downloadUrl, file.size, file.name);
          } else {
            rst = {
              id: uniqueKeyGenerator(),
              name: file.name,
              size: file.size,
              url: downloadUrl
            };
          }

          onSuccess?.(rst, downloadUrl);
          return;
        }

        onError?.({ [file.name]: `ä¸Šä¼ å¤±è´¥${xhr.responseText}` }, file, xhr);
      };
      xhr.send(formData);
    }
  };

  continuedUpload();

  return { continuedUpload };
};

export const defaultStaticMultiPartConfig = {
  partSize: 5,
  chunkUploadThreshold: 10,
  parallel: 4
};

export const defaultMultiPartConfig = {
  get runtimeConfig(): MultipartUploadRuntimeConfig {
    return ConfigHelper.getConfig(RuntimeConfig.getConfig('multipartUpload'));
  },
  get partSize() {
    return this.runtimeConfig.partSize || defaultStaticMultiPartConfig.partSize;
  },
  get chunkUploadThreshold() {
    return this.runtimeConfig.chunkUploadThreshold || defaultStaticMultiPartConfig.chunkUploadThreshold;
  },
  get parallel() {
    return this.runtimeConfig.parallel || defaultStaticMultiPartConfig.parallel;
  }
};

export const useUploadFileEvent = async (params: IUploadFileEventParams) => {
  const {
    file,
    accept,
    cdnKey,
    uploadMethod,
    managed,
    partSize = defaultMultiPartConfig.partSize,
    chunkUploadThreshold = defaultMultiPartConfig.chunkUploadThreshold,
    parallel = defaultMultiPartConfig.parallel,
    onSuccess,
    onError,
    onProgress
  } = params;

  const totalSize = file.size;
  const chunkSize = partSize * 1024 * 1024;
  const chunks = Math.ceil(totalSize / chunkSize);
  const fileChunks: Blob[] = [];
  let chunkFiles: UploadChunkFile[] = [];

  const M = file.size / 1024 / 1024;

  let start = true;

  if (chunkUploadThreshold && chunkUploadThreshold > M) {
    start = false;
  }

  if (start) {
    for (let i = 0; i < chunks; i++) {
      const fileChunk = file.slice(i * chunkSize, (i + 1) * chunkSize);
      fileChunks.push(fileChunk);
      chunkFiles.push({
        partNumber: i + 1,
        fileSize: fileChunk.size
      });
    }
  }

  const { singleUploadData, multipartUploadData, downloadUrl } = await getFileSignature(file.name, cdnKey, {
    size: totalSize,
    accept,
    type: file.type,
    chunkFiles
  });

  // åˆ†ç‰‡ä¸Šä¼ 
  if (uploadMethod === IUploadMethod.Multipart && multipartUploadData && start) {
    const { continuedUpload } = await useMultipartUpload({
      multipartUploadData,
      file,
      fileChunks,
      chunkSize,
      downloadUrl,
      parallel,
      managed,
      onSuccess,
      onError,
      onProgress
    });
    return continuedUpload;
  }
  // ç›´ä¼ 
  const { continuedUpload } = await useSingleUpload({
    singleUploadData,
    file,
    downloadUrl,
    managed,
    onSuccess,
    onError,
    onProgress
  });
  return continuedUpload;
};
